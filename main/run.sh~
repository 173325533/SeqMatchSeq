#!/bin/bash



for optimizer in  adagrad
do
		
		for dropoutP in 0.1 0.2 0
		do
			for rho in 0 0.0001 0.0003
			do
				th main.lua -task paraphrase -model LSTMSim -mem_dim 300 -reg $rho -learning_rate 0.001 -dropoutP $dropoutP
			done
		done
done
